{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c90306",
   "metadata": {},
   "source": [
    "**Aim: Write a program to demonstrate the change in accuracy/loss/convergence time with change in \n",
    "optimizers like stochastic gradient descent, adam, adagrad, RMSprop and Nadam for any suitable \n",
    "application**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d8109f",
   "metadata": {},
   "source": [
    "Objectives: \n",
    "1. To learn optimization algorithms \n",
    "2. To learn and understand hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87d8e6",
   "metadata": {},
   "source": [
    "Theory: \n",
    "\n",
    "SGD, Adam, RMSprop, Nadam \n",
    "The word ‘stochastic‘means a system or a process that is linked with a random probability. Hence, in \n",
    "Stochastic Gradient Descent, a few samples are selected randomly instead of the whole data set for \n",
    "each iteration. In Gradient Descent, there is a term called “batch” which denotes the total number of \n",
    "samples from a dataset that is used for calculating the gradient for each iteration. In typical Gradient \n",
    "Descent optimization, like Batch Gradient Descent, the batch is taken to be the whole dataset. \n",
    "Although, using the whole dataset is really useful for getting to the minima in a less noisy and less \n",
    "random manner, but the problem arises when our datasets gets big. \n",
    "Adam is a replacement optimization algorithm for stochastic gradient descent for training deep \n",
    "learning models. Adam combines the best properties of the AdaGrad and RMSProp algorithms to \n",
    "provide an optimization algorithm that can handle sparse gradients on noisy problems. \n",
    "The RMSprop optimizer is similar to the gradient descent algorithm with momentum. The RMSprop \n",
    "optimizer restricts the oscillations in the vertical direction. Therefore, we can increase our learning \n",
    "rate and our algorithm could take larger steps in the horizontal direction converging faster. The \n",
    "difference between RMSprop and gradient descent is on how the gradients are calculated. The \n",
    "following equations show how the gradients are calculated for the RMSprop and gradient descent \n",
    "with momentum. The value of momentum is denoted by beta and is usually set to 0.9. \n",
    "Nadam combines NAG and Adam. Nadam is employed for noisy gradients or for gradients with high \n",
    "curvatures. The learning process is accelerated by summing up the exponential decay of the moving \n",
    "averages for the previous and current gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00cbb0e",
   "metadata": {},
   "source": [
    "Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ff2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers,models,datasets \n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ecd39fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images,train_labels),(test_images,test_labels)=datasets.cifar100.load_data() \n",
    "train_images=train_images/255 \n",
    "test_images=test_images/255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0c803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.0533 - loss: 4.5279 - val_accuracy: 0.1159 - val_loss: 3.8610\n",
      "Epoch 2/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.1314 - loss: 3.7814 - val_accuracy: 0.1515 - val_loss: 3.7106\n",
      "Epoch 3/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.1625 - loss: 3.6146 - val_accuracy: 0.1705 - val_loss: 3.6002\n",
      "Epoch 4/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.1851 - loss: 3.4920 - val_accuracy: 0.1800 - val_loss: 3.5515\n",
      "Epoch 5/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.1953 - loss: 3.4132 - val_accuracy: 0.1929 - val_loss: 3.5004\n",
      "Epoch 6/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.2090 - loss: 3.3473 - val_accuracy: 0.2010 - val_loss: 3.4430\n",
      "Epoch 7/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.2164 - loss: 3.3060 - val_accuracy: 0.1977 - val_loss: 3.4360\n",
      "Epoch 8/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.2315 - loss: 3.2207 - val_accuracy: 0.2029 - val_loss: 3.4108\n",
      "Epoch 9/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.2412 - loss: 3.1775 - val_accuracy: 0.2206 - val_loss: 3.3370\n",
      "Epoch 10/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.2495 - loss: 3.1288 - val_accuracy: 0.2127 - val_loss: 3.3565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23a7f0121e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base=VGG16(include_top=False,input_shape=(32,32,3)) \n",
    "base.trainable=False \n",
    "model=models.Sequential() \n",
    "model.add(layers.Flatten()) \n",
    "model.add(layers.Dense(1200,activation=\"relu\")) \n",
    "model.add(layers.Dense(100,activation=\"softmax\")) \n",
    "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=\n",
    "[\"accuracy\"]) \n",
    "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db186dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.2719 - loss: 3.0147 - val_accuracy: 0.2403 - val_loss: 3.2510\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.2859 - loss: 2.9660 - val_accuracy: 0.2447 - val_loss: 3.2415\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.2881 - loss: 2.9606 - val_accuracy: 0.2448 - val_loss: 3.2360\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.2885 - loss: 2.9569 - val_accuracy: 0.2448 - val_loss: 3.2321\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.2892 - loss: 2.9478 - val_accuracy: 0.2460 - val_loss: 3.2296\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.2947 - loss: 2.9356 - val_accuracy: 0.2450 - val_loss: 3.2280\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.2941 - loss: 2.9295 - val_accuracy: 0.2460 - val_loss: 3.2262\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.2933 - loss: 2.9338 - val_accuracy: 0.2448 - val_loss: 3.2246\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.2929 - loss: 2.9312 - val_accuracy: 0.2450 - val_loss: 3.2235\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.2924 - loss: 2.9214 - val_accuracy: 0.2448 - val_loss: 3.2227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23a7f03b7d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"sgd\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"]) \n",
    "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e970365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.2917 - loss: 2.9275 - val_accuracy: 0.2453 - val_loss: 3.2219\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.2925 - loss: 2.9297 - val_accuracy: 0.2453 - val_loss: 3.2217\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.2977 - loss: 2.9220 - val_accuracy: 0.2452 - val_loss: 3.2214\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.2946 - loss: 2.9289 - val_accuracy: 0.2459 - val_loss: 3.2211\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.2978 - loss: 2.9177 - val_accuracy: 0.2457 - val_loss: 3.2208\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.2969 - loss: 2.9134 - val_accuracy: 0.2459 - val_loss: 3.2206\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.2934 - loss: 2.9237 - val_accuracy: 0.2457 - val_loss: 3.2204\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.2978 - loss: 2.9184 - val_accuracy: 0.2457 - val_loss: 3.2202\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.2953 - loss: 2.9155 - val_accuracy: 0.2454 - val_loss: 3.2200\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.2892 - loss: 2.9328 - val_accuracy: 0.2455 - val_loss: 3.2198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23a7edd92b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adagrad\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"]) \n",
    "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa45956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.2196 - loss: 3.4991 - val_accuracy: 0.2043 - val_loss: 3.4704\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.2505 - loss: 3.1410 - val_accuracy: 0.2073 - val_loss: 3.4186\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 117ms/step - accuracy: 0.2545 - loss: 3.1191 - val_accuracy: 0.2214 - val_loss: 3.3732\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.2575 - loss: 3.1021 - val_accuracy: 0.2250 - val_loss: 3.3299\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 101ms/step - accuracy: 0.2600 - loss: 3.0806 - val_accuracy: 0.2248 - val_loss: 3.3344\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.2595 - loss: 3.0682 - val_accuracy: 0.2262 - val_loss: 3.3191\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 101ms/step - accuracy: 0.2658 - loss: 3.0390 - val_accuracy: 0.2005 - val_loss: 3.4726\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.2622 - loss: 3.0573 - val_accuracy: 0.2170 - val_loss: 3.3857\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.2691 - loss: 3.0329 - val_accuracy: 0.2255 - val_loss: 3.3138\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.2743 - loss: 3.0043 - val_accuracy: 0.2242 - val_loss: 3.3236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23a7effebd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"]) \n",
    "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2576f624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.2986 - loss: 2.8901 - val_accuracy: 0.2531 - val_loss: 3.2010\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.3139 - loss: 2.8185 - val_accuracy: 0.2539 - val_loss: 3.1949\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.3209 - loss: 2.8102 - val_accuracy: 0.2555 - val_loss: 3.1929\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.3186 - loss: 2.7999 - val_accuracy: 0.2542 - val_loss: 3.1917\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.3197 - loss: 2.7938 - val_accuracy: 0.2556 - val_loss: 3.1913\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.3230 - loss: 2.7971 - val_accuracy: 0.2556 - val_loss: 3.1900\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.3189 - loss: 2.7917 - val_accuracy: 0.2555 - val_loss: 3.1896\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.3187 - loss: 2.7943 - val_accuracy: 0.2556 - val_loss: 3.1897\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.3209 - loss: 2.7853 - val_accuracy: 0.2557 - val_loss: 3.1889\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.3232 - loss: 2.7829 - val_accuracy: 0.2556 - val_loss: 3.1884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23a7efee810>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"sgd\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"]) \n",
    "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64c74bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - accuracy: 0.3028 - loss: 2.8646 - val_accuracy: 0.2513 - val_loss: 3.2085\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 144ms/step - accuracy: 0.3143 - loss: 2.7969 - val_accuracy: 0.2502 - val_loss: 3.1991\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.3210 - loss: 2.7768 - val_accuracy: 0.2517 - val_loss: 3.2025\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.3257 - loss: 2.7563 - val_accuracy: 0.2496 - val_loss: 3.2006\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.3260 - loss: 2.7414 - val_accuracy: 0.2512 - val_loss: 3.2061\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.3345 - loss: 2.7270 - val_accuracy: 0.2544 - val_loss: 3.1917\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.3367 - loss: 2.6993 - val_accuracy: 0.2521 - val_loss: 3.1971\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.3405 - loss: 2.6855 - val_accuracy: 0.2582 - val_loss: 3.1889\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.3461 - loss: 2.6510 - val_accuracy: 0.2522 - val_loss: 3.2017\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - accuracy: 0.3482 - loss: 2.6484 - val_accuracy: 0.2530 - val_loss: 3.2006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23a7f08f0b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"nadam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"]) \n",
    "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
